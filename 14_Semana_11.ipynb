{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img width=\"300px\" src=\"https://cachimbo.pe/wp-content/uploads/2022/10/1-19.jpg\"></img>\n",
        "\n",
        "#**Matemática y Estadística para Ciencia de Datos**\n",
        "## **Tema: Aprendizaje Profundo**\n",
        "#### **Docente: Giron Rene Omar A.**\n",
        "\n",
        "---------------"
      ],
      "metadata": {
        "id": "gIEzjl6hT017"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funciones de Activación"
      ],
      "metadata": {
        "id": "l9RVBRGvLlxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Función de activación sigmoide\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Función de activación ReLU (Rectified Linear Unit)\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# Función de activación tangente hiperbólica\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Datos de ejemplo\n",
        "x = np.linspace(-10, 10, 100)\n",
        "\n",
        "# Calcular las funciones de activación\n",
        "y_sigmoid = sigmoid(x)\n",
        "y_relu = relu(x)\n",
        "y_tanh = tanh(x)\n",
        "\n",
        "# Graficar las funciones de activación\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(x, y_sigmoid)\n",
        "plt.title('Función Sigmoide')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(x, y_relu)\n",
        "plt.title('Función ReLU')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(x, y_tanh)\n",
        "plt.title('Función Tangente Hiperbólica')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GrZHzjNo-ok_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron"
      ],
      "metadata": {
        "id": "2qbcJ45hvKvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron 1"
      ],
      "metadata": {
        "id": "BK87N3BiSSu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def perceptron_learning_algorithm(P, N, max_iterations=1000):\n",
        "    \"\"\"\n",
        "    Algoritmo de aprendizaje del perceptrón.\n",
        "\n",
        "    Args:\n",
        "        P (list): Lista de vectores de entrada con etiqueta 1.\n",
        "        N (list): Lista de vectores de entrada con etiqueta 0.\n",
        "        max_iterations (int): Número máximo de iteraciones para evitar bucles infinitos.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Vector de pesos aprendidos.\n",
        "    \"\"\"\n",
        "    # Inicializar pesos aleatoriamente\n",
        "    num_features = len(P[0])\n",
        "    w = np.random.randn(num_features)\n",
        "    w0=w\n",
        "    # Concatenar P y N\n",
        "    X = P + N\n",
        "    y = [1] * len(P) + [0] * len(N)\n",
        "\n",
        "    # Convertir a numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    iterations = 0\n",
        "    while iterations < max_iterations:\n",
        "        misclassified = False\n",
        "        for i in range(len(X)):\n",
        "            if y[i] == 1 and np.dot(w, X[i]) < 0:\n",
        "                w = w + X[i]\n",
        "                misclassified = True\n",
        "            elif y[i] == 0 and np.dot(w, X[i]) >= 0:\n",
        "                w = w - X[i]\n",
        "                misclassified = True\n",
        "\n",
        "        # Si no hubo errores en la clasificación, el algoritmo ha convergido\n",
        "        if not misclassified:\n",
        "            print(f\"Converged after {iterations} iterations.\")\n",
        "            break\n",
        "\n",
        "        iterations += 1\n",
        "\n",
        "    if iterations == max_iterations:\n",
        "        print(\"Reached maximum iterations without convergence.\")\n",
        "\n",
        "    return w0,w\n",
        "\n",
        "# Datos de ejemplo\n",
        "P = [[2, 3], [4, 5]]\n",
        "N = [[1, 0], [0, 1]]\n",
        "\n",
        "# Ejecutar el algoritmo\n",
        "w0, weights = perceptron_learning_algorithm(P, N)\n",
        "\n",
        "print(\"Pesos aleatorios:\", w0)\n",
        "print(\"Pesos aprendidos:\", weights)"
      ],
      "metadata": {
        "id": "jK2Mekxl5vlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron 2"
      ],
      "metadata": {
        "id": "UCjHLey6SRSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def perceptron_learning_algorithm(P, N, max_iterations=1000):\n",
        "    \"\"\"\n",
        "    Algoritmo de aprendizaje del perceptrón.\n",
        "\n",
        "    Args:\n",
        "        P (list): Lista de vectores de entrada con etiqueta 1.\n",
        "        N (list): Lista de vectores de entrada con etiqueta 0.\n",
        "        max_iterations (int): Número máximo de iteraciones para evitar bucles infinitos.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Vector de pesos aprendidos.\n",
        "    \"\"\"\n",
        "    # Inicializar pesos aleatoriamente\n",
        "    num_features = len(P[0])\n",
        "    w = np.random.randn(num_features + 1)  # +1 para el término de sesgo\n",
        "\n",
        "    # Concatenar P y N\n",
        "    X = P + N\n",
        "    y = [1] * len(P) + [0] * len(N)\n",
        "\n",
        "    # Convertir a numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Añadir un término de sesgo (columna de 1s) a X\n",
        "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "\n",
        "    iterations = 0\n",
        "    while iterations < max_iterations:\n",
        "        misclassified = False\n",
        "        for i in range(len(X)):\n",
        "            if y[i] == 1 and np.dot(w, X[i]) <= 0:\n",
        "                w = w + X[i]\n",
        "                misclassified = True\n",
        "            elif y[i] == 0 and np.dot(w, X[i]) > 0:\n",
        "                w = w - X[i]\n",
        "                misclassified = True\n",
        "\n",
        "        # Si no hubo errores en la clasificación, el algoritmo ha convergido\n",
        "        if not misclassified:\n",
        "            print(f\"Converged after {iterations} iterations.\")\n",
        "            break\n",
        "\n",
        "        iterations += 1\n",
        "\n",
        "    if iterations == max_iterations:\n",
        "        print(\"Reached maximum iterations without convergence.\")\n",
        "\n",
        "    return w\n",
        "\n",
        "def predict(weights, X):\n",
        "    \"\"\"\n",
        "    Función de predicción del perceptrón.\n",
        "\n",
        "    Args:\n",
        "        weights (np.ndarray): Vector de pesos aprendidos.\n",
        "        X (list): Lista de vectores de entrada a clasificar.\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de etiquetas predichas (0 o 1).\n",
        "    \"\"\"\n",
        "    # Convertir a numpy array y añadir un término de sesgo (columna de 1s)\n",
        "    X = np.array(X)\n",
        "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "\n",
        "    predictions = []\n",
        "    for x in X:\n",
        "        prediction = 1 if np.dot(weights, x) > 0 else 0\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "PaxsFpbHsrN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Más datos de ejemplo\n",
        "P = [[2, 3], [4, 5], [3, 6], [5, 8], [1, 4]]\n",
        "N = [[1, 0], [0, 1], [2, 1], [1, 2], [0, 0]]\n",
        "\n",
        "# Ejecutar el algoritmo\n",
        "weights = perceptron_learning_algorithm(P, N)\n",
        "print(\"Pesos aprendidos:\", weights)"
      ],
      "metadata": {
        "id": "1LNzbkMvsrJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datos de prueba\n",
        "X_test = [[2, 3], [4, 4], [1, 1], [6, 7]]\n",
        "predictions = predict(weights, X_test)\n",
        "print(\"Predicciones:\", predictions)"
      ],
      "metadata": {
        "id": "pp2Fhj705Vic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perceptron 3"
      ],
      "metadata": {
        "id": "UDSmC8IgSNkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def perceptron_learning_algorithm(P, N, max_iterations=1000):\n",
        "    \"\"\"\n",
        "    Algoritmo de aprendizaje del perceptrón.\n",
        "\n",
        "    Args:\n",
        "        P (list): Lista de vectores de entrada con etiqueta 1.\n",
        "        N (list): Lista de vectores de entrada con etiqueta 0.\n",
        "        max_iterations (int): Número máximo de iteraciones para evitar bucles infinitos.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Vector de pesos aprendidos.\n",
        "    \"\"\"\n",
        "    # Inicializar pesos aleatoriamente\n",
        "    num_features = len(P[0])\n",
        "    w = np.random.randn(num_features + 1)  # +1 para el término de sesgo\n",
        "\n",
        "    # Concatenar P y N\n",
        "    X = P + N\n",
        "    y = [1] * len(P) + [0] * len(N)\n",
        "\n",
        "    # Convertir a numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Añadir un término de sesgo (columna de 1s) a X\n",
        "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "\n",
        "    iterations = 0\n",
        "    while iterations < max_iterations:\n",
        "        misclassified = False\n",
        "        for i in range(len(X)):\n",
        "            if y[i] == 1 and np.dot(w, X[i]) <= 0:\n",
        "                w = w + X[i]\n",
        "                misclassified = True\n",
        "            elif y[i] == 0 and np.dot(w, X[i]) > 0:\n",
        "                w = w - X[i]\n",
        "                misclassified = True\n",
        "\n",
        "        # Si no hubo errores en la clasificación, el algoritmo ha convergido\n",
        "        if not misclassified:\n",
        "            print(f\"Converged after {iterations} iterations.\")\n",
        "            break\n",
        "\n",
        "        iterations += 1\n",
        "\n",
        "    if iterations == max_iterations:\n",
        "        print(\"Reached maximum iterations without convergence.\")\n",
        "\n",
        "    return w\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def predict_probabilities(weights, X):\n",
        "    \"\"\"\n",
        "    Función de predicción del perceptrón que devuelve probabilidades.\n",
        "\n",
        "    Args:\n",
        "        weights (np.ndarray): Vector de pesos aprendidos.\n",
        "        X (list): Lista de vectores de entrada a clasificar.\n",
        "\n",
        "    Returns:\n",
        "        list: Lista de probabilidades predichas.\n",
        "    \"\"\"\n",
        "    # Convertir a numpy array y añadir un término de sesgo (columna de 1s)\n",
        "    X = np.array(X)\n",
        "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "\n",
        "    probabilities = []\n",
        "    for x in X:\n",
        "        probability = sigmoid(np.dot(weights, x))\n",
        "        probabilities.append(probability)\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "# Generar datos de ejemplo usando sklearn\n",
        "X, y = make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=42)\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Separar los datos de entrenamiento en P y N\n",
        "P_train = [x.tolist() for x, label in zip(X_train, y_train) if label == 1]\n",
        "N_train = [x.tolist() for x, label in zip(X_train, y_train) if label == 0]\n",
        "\n",
        "# Entrenar el algoritmo\n",
        "weights = perceptron_learning_algorithm(P_train, N_train)\n",
        "print(\"Pesos aprendidos:\", weights)\n",
        "\n",
        "# Hacer predicciones de probabilidad en el conjunto de prueba\n",
        "probabilities = predict_probabilities(weights, X_test)\n",
        "print(\"Probabilidades:\", probabilities)\n",
        "\n",
        "# Convertir probabilidades a predicciones binarias\n",
        "predictions = [1 if prob > 0.5 else 0 for prob in probabilities]\n",
        "print(\"Predicciones:\", predictions)\n",
        "\n",
        "# Evaluar el rendimiento\n",
        "accuracy = np.mean(predictions == y_test)\n",
        "print(\"Precisión:\", accuracy)\n",
        "\n",
        "# Graficar los datos y la frontera de decisión\n",
        "def plot_decision_boundary(X, y, weights):\n",
        "    # Crear una malla para la gráfica\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                         np.arange(y_min, y_max, 0.01))\n",
        "\n",
        "    # Calcula la probabilidad para cada punto en la malla\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "    grid = np.hstack((np.ones((grid.shape[0], 1)), grid))  # Añadir el término de sesgo\n",
        "    probs = sigmoid(np.dot(grid, weights)).reshape(xx.shape)\n",
        "\n",
        "    # Contorno y etiquetas de datos\n",
        "    plt.contourf(xx, yy, probs, alpha=0.8, cmap=plt.cm.Spectral)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o', cmap=plt.cm.Spectral)\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.title('Decision Boundary')\n",
        "    plt.show()\n",
        "\n",
        "# Graficar la frontera de decisión\n",
        "plot_decision_boundary(X_test, y_test, weights)\n"
      ],
      "metadata": {
        "id": "IkBO7nUjuDIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RN con Sklearn"
      ],
      "metadata": {
        "id": "84mskYsQMMUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_circles\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generamos un conjunto de datos de círculos concéntricos\n",
        "X, y = make_circles(n_samples=1000, noise=0.1, factor=0.2, random_state=42)\n",
        "\n",
        "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creamos un Perceptrón Multicapa (MLP) con una capa oculta de 64 neuronas\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(64,), max_iter=500, alpha=1e-4,\n",
        "                    solver='sgd', verbose=10, random_state=42, tol=1e-4)\n",
        "\n",
        "# Entrenamos el MLP\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Realizamos predicciones en el conjunto de prueba\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Evaluamos la precisión del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Precisión del Perceptrón Multicapa (MLP): {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "Im7qdLcq7xaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizamos los datos\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X[y == 0, 0], X[y == 0, 1], marker='o', label='Clase 0')\n",
        "plt.scatter(X[y == 1, 0], X[y == 1, 1], marker='^', label='Clase 1')\n",
        "plt.legend()\n",
        "plt.title('Conjunto de datos de círculos concéntricos')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Podu11fy7xXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RN full codigo"
      ],
      "metadata": {
        "id": "pXTw5Vd3M9Z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ver el otro notebook"
      ],
      "metadata": {
        "id": "J7Z1Y_60uDDT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}